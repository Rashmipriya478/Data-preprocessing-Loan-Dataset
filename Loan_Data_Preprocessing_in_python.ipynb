{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries"
      ],
      "metadata": {
        "id": "ZOh_3GMkGKQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'os' module provides functions for interacting with the operating system\n",
        "import os\n",
        "\n",
        "# 'Numpy' is used for mathematical operations on large, multi-dimensional arrays and matrices\n",
        "import numpy as np\n",
        "\n",
        "# 'Pandas' is used for data manipulation and analysis\n",
        "import pandas as pd\n",
        "\n",
        "# 'Matplotlib' is a data visualization library for 2D and 3D plots, built on numpy\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# 'Seaborn' is based on matplotlib; used for plotting statistical graphics\n",
        "import seaborn as sns\n",
        "\n",
        "# to suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "PzWN3ekeGVNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing and Exploration of the dataset"
      ],
      "metadata": {
        "id": "y24C_8VFGhA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the data and setting the unique client_id as the index::\n",
        "\n",
        "df = pd.read_csv('/content/loans.csv', index_col = 'client_id')"
      ],
      "metadata": {
        "id": "u2Rkd_mQGqeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# showing the first 5 rows of the dataset:\n",
        "df.head()"
      ],
      "metadata": {
        "id": "6e87K2DnHOZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To check the Dimensions of the dataset:\n",
        "df.shape"
      ],
      "metadata": {
        "id": "TXuMto-MHYE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the info of the data:\n",
        "df.info()"
      ],
      "metadata": {
        "id": "BrWbR1zKHbDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Checking the datatypes of the columns"
      ],
      "metadata": {
        "id": "xh5BUNZGHj02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "a-1oFIK3HnzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Converting the data types of columns\n",
        "\n",
        "- loan_id to object\n",
        "- repaid to category dtype\n",
        "- loan_start and loan_end to date type"
      ],
      "metadata": {
        "id": "9hP6p4SVHsFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loan_id:\n",
        "\n",
        "df['loan_id'] = df['loan_id'].astype('object')\n",
        "\n",
        "# repaid:\n",
        "\n",
        "df['repaid'] = df['repaid'].astype('category')"
      ],
      "metadata": {
        "id": "wg_Nh2bPHxvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loan_start:\n",
        "\n",
        "df['loan_start'] = pd.to_datetime(df['loan_start'], format = '%Y-%m-%d')\n",
        "\n",
        "\n",
        "# loan_end:\n",
        "\n",
        "df['loan_end'] = pd.to_datetime(df['loan_end'], format = '%Y-%m-%d')"
      ],
      "metadata": {
        "id": "GvIfw3SMHzxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Checking the datatypes again:"
      ],
      "metadata": {
        "id": "IgglNZWWH6rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "PByL9B4oH4t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary Statistics of the data"
      ],
      "metadata": {
        "id": "fGZ1oifmIEZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary Statistics for Numerical data:\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "tuZw9mW3IHXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary Statistics for Categorical data:\n",
        "df.describe(exclude=[np.number])"
      ],
      "metadata": {
        "id": "QENO_wQ2ILq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Missing Values"
      ],
      "metadata": {
        "id": "xEbPUjKBIYm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use isnull().sum() to check for missing values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "mt21SFINIaQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no missing values in the data."
      ],
      "metadata": {
        "id": "_F53MQejIiqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Outliers Treatment"
      ],
      "metadata": {
        "id": "jD-dPA6kIp59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check presence of outlier, we plot box plot."
      ],
      "metadata": {
        "id": "v4FLCJtuIv4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For loan_amount\n",
        "df['loan_amount'].plot(kind='box')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JhyuxIC6IrBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For rate\n",
        "df['rate'].plot(kind='box')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "suHfYMLPI9Xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that there are no outliers in the loan_amount column and some outliers are present in the rate column. To treat for outliers can either cap the values or transform the data. I Shall demonstrate both the approaches here."
      ],
      "metadata": {
        "id": "_Vg0hitzJMH4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformation\n",
        "\n",
        "SQRT transformation"
      ],
      "metadata": {
        "id": "0ONuuqfqJPhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['SQRT_RATE'] = df['rate']**0.5"
      ],
      "metadata": {
        "id": "gnDsRh68JNWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['sqrt_rate'] = np.sqrt(df['rate'])"
      ],
      "metadata": {
        "id": "z-gwVycyJX2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "EU1n76r2JYrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the skewness, kurtosis between the original and transformed data:\n",
        "print(\"The skewness of the original data is {}\".format(df.rate.skew()))\n",
        "print('The skewness of the SQRT transformed data is {}'.format(df.SQRT_RATE.skew()))\n",
        "\n",
        "print('')\n",
        "\n",
        "print(\"The kurtosis of the original data is {}\".format(df.rate.kurt()))\n",
        "print(\"The kurtosis of the SQRT transformed data is {}\".format(df.SQRT_RATE.kurt()))"
      ],
      "metadata": {
        "id": "psI205hzJf6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the distribution\n",
        "\n",
        "fig, axes = plt.subplots(1,2, figsize=(15,5))\n",
        "sns.distplot(df['rate'], ax=axes[0])\n",
        "sns.distplot(df['sqrt_rate'], ax=axes[1])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PaRw1bvcJkuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Result:\n",
        "\n",
        "The Rate column was right skewed earlier. The skewness and kurtosis as reduced significantly. The transformed SQRT rate, on the right graph resembles normal distribution now."
      ],
      "metadata": {
        "id": "7iYQ2OBwJnlj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Log Transformation"
      ],
      "metadata": {
        "id": "yiBi6UdSJxUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Log Rate'] = np.log(df['rate'])"
      ],
      "metadata": {
        "id": "dRP0EL5PJylf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "ZTlqvxi_J1pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The skewness of the original data is {}\".format(df.rate.skew()))\n",
        "print('The skewness of the SQRT transformed data is {}'.format(df.SQRT_RATE.skew()))\n",
        "print(\"The skewnss of the LOG transformed data is {}\".format(df['Log Rate'].skew()))\n",
        "\n",
        "print('')\n",
        "\n",
        "\n",
        "print(\"The kurtosis of the original data is {}\".format(df.rate.kurt()))\n",
        "print(\"The kurtosis of the SQRT transformed data is {}\".format(df.SQRT_RATE.kurt()))\n",
        "print(\"The kurtosis of the LOG transformed data is {}\".format(df['Log Rate'].kurt()))"
      ],
      "metadata": {
        "id": "FmbfXHDkJ8Ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the graph:\n",
        "\n",
        "fig, axes = plt.subplots(1,3,figsize=(15,5))\n",
        "\n",
        "sns.distplot(df['rate'], ax=axes[0])\n",
        "sns.distplot(df['SQRT_RATE'], ax=axes[1])\n",
        "sns.distplot(df['Log Rate'], ax=axes[2])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kOorTLeUJ-1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference:\n",
        "\n",
        "Log Transformation made the rate left skewed and more peaked.\n",
        "\n",
        "However, Log transformation is more closer to 0 and hence is more normal. Though it heavily maniupulates the data.\n",
        "\n",
        "In our case, square root transformation is more suitable.#"
      ],
      "metadata": {
        "id": "txNKn2N0KBdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Using Lambda function :\n",
        "\n",
        "df['LOG_Rate'] = df['rate'].apply(lambda x:np.log(x))"
      ],
      "metadata": {
        "id": "7obVtaZKKKlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "oPKjj8pDKNFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are other transformations available also called BoxCox. There is an inbuilt function in Sci-kit Learn library called PowerTransformer for this which can also be called to transform the data."
      ],
      "metadata": {
        "id": "vxyal-h9KXU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Outliers Treatment using Capping Approach"
      ],
      "metadata": {
        "id": "484GvTIhKatf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Z-Score approach to treat Outliers:\n",
        "\n",
        "All the values above 3 standard deviation and below -3 standard deviation are outliers and can be removed"
      ],
      "metadata": {
        "id": "WmbtDlJcKgWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the dataset and setting client id as index\n",
        "\n",
        "df1 = pd.read_csv('loans.csv', index_col = 'client_id')\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "nkuTo8M9KYJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loan_id:\n",
        "\n",
        "df1['loan_id'] = df1['loan_id'].astype('object')\n",
        "\n",
        "# repaid:\n",
        "\n",
        "df1['repaid'] = df1['repaid'].astype('category')"
      ],
      "metadata": {
        "id": "ECBhEJCvKmXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loan_start:\n",
        "\n",
        "df1['loan_start'] = pd.to_datetime(df1['loan_start'], format = '%Y-%m-%d')\n",
        "\n",
        "\n",
        "# loan_end:\n",
        "\n",
        "df1['loan_end'] = pd.to_datetime(df1['loan_end'], format = '%Y-%m-%d')"
      ],
      "metadata": {
        "id": "LpkPUYCWKpdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'SciPy' is used to perform scientific computations\n",
        "import scipy.stats as stats"
      ],
      "metadata": {
        "id": "nTI4oo_oKrYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using SciPy Library to calculate the Z-Score:"
      ],
      "metadata": {
        "id": "qGF8A3cIKtXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating new variable with Z-score of each record:\n",
        "df1['ZR'] = stats.zscore(df1['rate'])"
      ],
      "metadata": {
        "id": "XCulfOWYKvmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "w_d1ymz5KwCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combined Lower limit and Upper limit:\n",
        "\n",
        "df1[(df1['ZR']<-3) | (df1['ZR']>3)]"
      ],
      "metadata": {
        "id": "Ysc_xjqTKzFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count of outliers:\n",
        "\n",
        "df1[(df1['ZR']<-3) | (df1['ZR']>3)].shape[0]"
      ],
      "metadata": {
        "id": "GWzpv7WKK038"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Cleaned Data: without outliers so z>-3 and z< +3\n",
        "\n",
        "df2= df1[(df1['ZR']>-3) & (df1['ZR']<3)].reset_index()\n",
        "df2.head()"
      ],
      "metadata": {
        "id": "hcorKwB6K2jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.shape"
      ],
      "metadata": {
        "id": "BUIHGOSoK4Ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.shape"
      ],
      "metadata": {
        "id": "qCEyFcb6K5_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Interpretation:\n",
        "\n",
        "A crude way to know whether the outliers have been removed or not is to check the dimensions of the data. From the above output, we can see that the dimensions are reduced that implies outliers are removed."
      ],
      "metadata": {
        "id": "r77watXTLIVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df2.copy()"
      ],
      "metadata": {
        "id": "IGtw19ClLHpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.drop(columns = ['ZR'], inplace=True)\n",
        "df3.head()"
      ],
      "metadata": {
        "id": "KiIOaZeRLMjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IQR Method to treat Outliers:\n",
        "\n",
        "All the values below Q1 - 1.5IQR and values above Q3 + 1.5IQR are outliers and can be removed."
      ],
      "metadata": {
        "id": "D7kep7c8LQML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the Quantiles:\n",
        "\n",
        "Q1 = df3.rate.quantile(0.25)\n",
        "Q2 = df3.rate.quantile(0.50)\n",
        "Q3 = df3.rate.quantile(0.75)\n",
        "\n",
        "# IQR : Inter-Quartile Range\n",
        "\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Lower Limit:\n",
        "LC = Q1 - (1.5*IQR)\n",
        "\n",
        "# Upper Limit:\n",
        "UC = Q3 + (1.5*IQR)\n",
        "\n",
        "display(LC)\n",
        "display(UC)"
      ],
      "metadata": {
        "id": "foNSgQJHLSED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Plot\n",
        "\n",
        "sns.distplot(df3.rate)\n",
        "plt.axvline(UC, color='r')\n",
        "plt.axvline(LC, color ='r')\n",
        "plt.axvline(Q1, color='g')\n",
        "plt.axvline(Q3, color='g')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gbBipr1QLW3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find count of Outliers wrt IQR\n",
        "\n",
        "df3[(df3.rate<LC) | (df3.rate>UC)].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "9fW7f0JjLZte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3[(df3.rate<LC) | (df3.rate>UC)].shape[0]"
      ],
      "metadata": {
        "id": "UJAH1UBnLbqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Store the clean data wrt IQR:\n",
        "\n",
        "df4 = df3[(df3.rate>LC) & (df3.rate<UC)]\n",
        "df4.head()"
      ],
      "metadata": {
        "id": "RWQoP8ShLfP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.shape"
      ],
      "metadata": {
        "id": "QJu2TUBTLiMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4.shape"
      ],
      "metadata": {
        "id": "kqMyb2oRLi3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation:\n",
        "\n",
        "A crude way to know whether the outliers have been removed or not is to check the dimensions of the data. From the above output, we can see that the dimensions are reduced that implies outliers are removed."
      ],
      "metadata": {
        "id": "dpjv_ewVLmfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Box Plot for rate--- based on IQR Method\n",
        "\n",
        "sns.boxplot(df1.rate)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZHBKg7EzLoAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Box Plot for rate --- based on Z-score cleaned data\n",
        "\n",
        "sns.boxplot(df2.rate)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i6F_38gVLwNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Box Plot for rate --- based on IQR cleaned data\n",
        "\n",
        "sns.boxplot(df4.rate)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wywUYcYYLzEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Scaling the Numerical Features\n",
        "\n",
        "There are two ways to scale the data:\n",
        "\n",
        "Standardization (Z-Score)\\\n",
        "Normalization: Min Max Scalar\n",
        "Both can by done manually as well as have in-built functions in sklearn. Will demonstrate both."
      ],
      "metadata": {
        "id": "8DESszFlL3b1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardization (Z-Score)\n",
        "Scales the data using the formula (x-mean)/standard deviation"
      ],
      "metadata": {
        "id": "nj3MEZA7L9BA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manually:"
      ],
      "metadata": {
        "id": "Vh9uBfd3MAbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for Rate :\n",
        "avg_rate = df3['rate'].mean()\n",
        "avg_rate"
      ],
      "metadata": {
        "id": "nnJO7cyML792"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "std_rate = df3['rate'].std()\n",
        "std_rate"
      ],
      "metadata": {
        "id": "1BxJc1hZMETv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1 : transform using Z-score\n",
        "df3['Z_Score_Rate'] = (df3['rate'] - avg_rate)/std_rate"
      ],
      "metadata": {
        "id": "zyzL-ONIMGzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.head()"
      ],
      "metadata": {
        "id": "Y8PfcvS2MJbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking if the skewness and kurtosis post scaling or not:\n",
        "\n",
        "# For Rate:\n",
        "\n",
        "print(\"The skewness for the original data is {}.\".format(df3.rate.skew()))\n",
        "print(\"The kurtosis for the original data is {}.\".format(df3.rate.kurt()))\n",
        "\n",
        "print('')\n",
        "\n",
        "print(\"The skewness for the Zscore Scaled column is {}.\".format(df3.Z_Score_Rate.skew()))\n",
        "print(\"The kurtosis for the Zscore Scaled columns is {}.\".format(df3.Z_Score_Rate.kurt()))"
      ],
      "metadata": {
        "id": "w6M9U-LzML_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Loan_amount:\n",
        "avg_LA = df3['loan_amount'].mean()\n",
        "avg_LA"
      ],
      "metadata": {
        "id": "s2ZsHJg_MOmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "std_LA = df3['loan_amount'].std()\n",
        "std_LA"
      ],
      "metadata": {
        "id": "T9t6P90SMQbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1 : transform using Z-score\n",
        "df3['Z_Score_LA'] = (df3['loan_amount'] - avg_LA)/std_LA"
      ],
      "metadata": {
        "id": "7hMn9wWTMSQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "ebwhnDyvMTFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking if the skewness and kurtosis post scaling or not:\n",
        "\n",
        "# For Loan_amount:\n",
        "\n",
        "print(\"The skewness for the original data is {}.\".format(df3.loan_amount.skew()))\n",
        "print(\"The kurtosis for the original data is {}.\".format(df3.loan_amount.kurt()))\n",
        "\n",
        "print('')\n",
        "\n",
        "print(\"The skewness for the Zscore Scaled column is {}.\".format(df3.Z_Score_LA.skew()))\n",
        "print(\"The kurtosis for the Zscore Scaled columns is {}.\".format(df3.Z_Score_LA.kurt()))"
      ],
      "metadata": {
        "id": "aY49hbwxMWdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of the columns\n",
        "\n",
        "fig, axes = plt.subplots(2,2, figsize=(15,5))\n",
        "\n",
        "sns.distplot(df3['rate'], ax=axes[0,0])\n",
        "sns.distplot(df3['Z_Score_Rate'], ax=axes[0,1])\n",
        "sns.distplot(df3['loan_amount'], ax=axes[1,0])\n",
        "sns.distplot(df3['Z_Score_LA'], ax=axes[1,1])\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4TgTop1fMY22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The only difference between the two curves is of the Range on the x-axis. The impact of scaling on data is: Skewness, Kurtosis and Distribution all remain same.\n",
        "\n",
        "The need for Scaling is :\n",
        "\n",
        "Comparison between variables is easier\\\n",
        "Computation power is more efficient and less time consuming."
      ],
      "metadata": {
        "id": "QS9Eb0fnMdRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loans data:\n",
        "\n",
        "df4 = df3.copy()\n",
        "df4.drop(columns = ['Z_Score_Rate'], inplace=True)\n",
        "df4.head()"
      ],
      "metadata": {
        "id": "uyYClJ5DMijq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "Lp_e6HwqMlSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4_num = df[['loan_amount','rate']]\n",
        "df4_num.head()"
      ],
      "metadata": {
        "id": "FJI7hIFtMnRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SS = StandardScaler()\n",
        "\n",
        "scaled_x = SS.fit_transform(df4_num)\n",
        "scaled_x"
      ],
      "metadata": {
        "id": "reqgiIeaMpq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalization: Min Max Scalar\n",
        "\n",
        "Scales the data using the formula (x - min)/(max - min)"
      ],
      "metadata": {
        "id": "hqd_NwwyMukH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manually:"
      ],
      "metadata": {
        "id": "AP6otHv5MysT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ForeRate:\n",
        "min_rate = df4.rate.min()\n",
        "min_rate"
      ],
      "metadata": {
        "id": "tVPjGKrJMwVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_rate = df4.rate.max()\n",
        "max_rate"
      ],
      "metadata": {
        "id": "5Xs2etklM1_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df4['Min_Max_R'] = (df4['rate'] - min_rate)/ (max_rate - min_rate)"
      ],
      "metadata": {
        "id": "FYjSenlmM3r_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking if the skewness and kurtosis post scaling or not:\n",
        "\n",
        "# For Rate:\n",
        "\n",
        "print(\"The skewness for the original data is {}.\".format(df4.rate.skew()))\n",
        "print(\"The skewness for the Zscore Scaled column is {}.\".format(df3.Z_Score_Rate.skew()))\n",
        "print(\"The skewness for the Min Max Scaled Data is {}.\".format(df4.Min_Max_R.skew()))\n",
        "\n",
        "\n",
        "print('')\n",
        "\n",
        "print(\"The kurtosis for the original data is {}.\".format(df4.rate.kurt()))\n",
        "print(\"The kurtosis for the Zscore Scaled columns is {}.\".format(df3.Z_Score_Rate.kurt()))\n",
        "print(\"The kurtosis for the Min Max Scaled Data is {}.\".format(df4.Min_Max_R.kurt()))"
      ],
      "metadata": {
        "id": "bhqdYlT5M5qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of the columns\n",
        "\n",
        "# For Rate\n",
        "\n",
        "fig, axes = plt.subplots(1,3, figsize=(15,5))\n",
        "\n",
        "sns.distplot(df3['rate'], ax=axes[0])\n",
        "sns.distplot(df3['Z_Score_Rate'], ax=axes[1])\n",
        "sns.distplot(df4['Min_Max_R'], ax=axes[2])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7bxVy3SuM7c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Loan_amount:\n",
        "min_LA = df4.loan_amount.min()\n",
        "min_LA"
      ],
      "metadata": {
        "id": "mKAy5bAxM9QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_LA = df4.loan_amount.max()\n",
        "max_LA"
      ],
      "metadata": {
        "id": "zgIZLXhmND7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4['Min_Max_LA'] = (df4['loan_amount'] - min_LA)/ (max_LA - min_LA)"
      ],
      "metadata": {
        "id": "u53d1As2NFxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking if the skewness and kurtosis post scaling or not:\n",
        "\n",
        "# For Rate:\n",
        "\n",
        "print(\"The skewness for the original data is {}.\".format(df4.loan_amount.skew()))\n",
        "print(\"The skewness for the Zscore Scaled column is {}.\".format(df3.Z_Score_LA.skew()))\n",
        "print(\"The skewness for the Min Max Scaled Data is {}.\".format(df4.Min_Max_LA.skew()))\n",
        "\n",
        "\n",
        "print('')\n",
        "\n",
        "print(\"The kurtosis for the original data is {}.\".format(df4.loan_amount.kurt()))\n",
        "print(\"The kurtosis for the Zscore Scaled columns is {}.\".format(df3.Z_Score_LA.kurt()))\n",
        "print(\"The kurtosis for the Min Max Scaled Data is {}.\".format(df4.Min_Max_LA.kurt()))"
      ],
      "metadata": {
        "id": "G09yi6tcNIBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of the columns\n",
        "\n",
        "# For Loan_Amount\n",
        "\n",
        "fig, axes = plt.subplots(1,3, figsize=(15,5))\n",
        "\n",
        "sns.distplot(df3['loan_amount'], ax=axes[0])\n",
        "sns.distplot(df3['Z_Score_LA'], ax=axes[1])\n",
        "sns.distplot(df4['Min_Max_LA'], ax=axes[2])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xg0_Z5wANKk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By Sklearn:"
      ],
      "metadata": {
        "id": "sL1aNxNeNOqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "k1l1OS9mNQbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MS = MinMaxScaler()\n",
        "\n",
        "MinMaxScaled = MS.fit_transform(df4_num)\n",
        "MinMaxScaled"
      ],
      "metadata": {
        "id": "Y39_M4juNSK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Few things to keep in mind:\n",
        "With Scaling all three - Skewness, Kurtosis and distribution remain same so there is no impact on outliers as well."
      ],
      "metadata": {
        "id": "DkhaaJopNeZy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Encoding the Categorical Features\n",
        "\n",
        "There are two ways to encode the categorical data into dummyvariables. Using:\n",
        "\n",
        "pd.get_dummies\\\n",
        "sklearn's in-built function of OneHotEncoder and LabelEncoder"
      ],
      "metadata": {
        "id": "u3kqLeWjNgRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loans data:\n",
        "\n",
        "df_loans = df3.copy()"
      ],
      "metadata": {
        "id": "HRBCQc6rNkrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_loans.drop(columns = ['Z_Score_Rate'], inplace=True)\n",
        "df_loans.drop(columns = ['Z_Score_LA'], inplace=True)"
      ],
      "metadata": {
        "id": "I5fNon0wNndh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_loans.head()"
      ],
      "metadata": {
        "id": "mtJOjYw7NpL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_loans.dtypes"
      ],
      "metadata": {
        "id": "VKtJBB9HNryG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Repaid is also a categoriy columns and creating dummies for loan_type\n",
        "df_loans.repaid.head()"
      ],
      "metadata": {
        "id": "W3GBAy6qNufY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.pd.get_dummies approach:"
      ],
      "metadata": {
        "id": "NcGlT5ALNxMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_cat = pd.get_dummies(df_loans['loan_type'], drop_first = True)\n",
        "dummy_cat.head()\n",
        "\n",
        "# drop_first = True drops the first column for each feature"
      ],
      "metadata": {
        "id": "vboTbsBXN2LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.OneHot Encoding"
      ],
      "metadata": {
        "id": "JugHPCZyN5jM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "Hi-KV-TBOCf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OE_tips = OneHotEncoder(drop ='first').fit(df_loans[['loan_type']])\n",
        "OE_tips.categories_"
      ],
      "metadata": {
        "id": "t1CLin9oOH0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Label Encoding"
      ],
      "metadata": {
        "id": "rj0mjI41OKTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "Vq3UktJYOMEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LE = LabelEncoder()\n",
        "\n",
        "LE_tips = LE.fit(df_loans[['loan_type']])"
      ],
      "metadata": {
        "id": "nWB0c5FNONqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LE_tips.classes_"
      ],
      "metadata": {
        "id": "Q0mLVvpgOPhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transform any new values to Dummy variables via Label Encoder\n",
        "LE_tips.transform(['other', 'cash', 'home', 'credit'])"
      ],
      "metadata": {
        "id": "njDzA9d7OS8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse transform to get original values from the dummy variables:\n",
        "LE_tips.inverse_transform([1,2,3,0])"
      ],
      "metadata": {
        "id": "DgtAn9-iOVAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating new Derived Features\n",
        "\n",
        "We can use the loan_start and loan_end features to calculate the tenure of the loan"
      ],
      "metadata": {
        "id": "x1GxipfXOYt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime as dt"
      ],
      "metadata": {
        "id": "gPIyJ7CEOcZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_loans['loan_tenure'] =  df_loans['loan_end'] - df_loans['loan_start']"
      ],
      "metadata": {
        "id": "NSnKuL0_OeQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_loans.head()"
      ],
      "metadata": {
        "id": "vWNQdC_HOgAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_loans.dtypes"
      ],
      "metadata": {
        "id": "A_wzJ5fpOiuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of days in the tenure are currently in TimeDelta, we want it integer hence will do the conversion as follows:"
      ],
      "metadata": {
        "id": "L4jT73n6Oli0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_loans['loan_tenure'] = df_loans['loan_tenure'].dt.days\n",
        "df_loans['loan_tenure']"
      ],
      "metadata": {
        "id": "oZL66I1bOmMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Tenure in number of Years:\n",
        "\n",
        "df_loans['loan_tenure'] = df_loans['loan_tenure']/365\n",
        "df_loans['loan_tenure']"
      ],
      "metadata": {
        "id": "p3v6u9AhOpyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training and Testing data"
      ],
      "metadata": {
        "id": "SQrSmoQbOt_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "LFxzxmrCOsHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Splitting for X and Y variables:\n",
        "\n",
        "Y = df_loans['loan_amount']\n",
        "X = df_loans.drop('loan_amount', axis=1)"
      ],
      "metadata": {
        "id": "SSd7idRdOy1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Independent Variable\n",
        "\n",
        "X.head()"
      ],
      "metadata": {
        "id": "8bQMN6nAO0_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependent or Target Variable\n",
        "\n",
        "Y.head()"
      ],
      "metadata": {
        "id": "nc42XWLNO3I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Splitting dataset into 80% Training and 20% Testing Data:\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,train_size=0.8, random_state =0)\n",
        "\n",
        "# random_state ---> is seed -- fixing the sample selection for Training & Testing dataset\n",
        "\n",
        "# check the dimensions of the train & test subset for\n",
        "\n",
        "print(\"The shape of X_train is:\", X_train.shape)\n",
        "print(\"The shape of X_test is:\", X_test.shape)\n",
        "\n",
        "print('')\n",
        "print(\"The shape of Y_train is:\", Y_train.shape)\n",
        "print(\"The shape of Y_test is:\", Y_test.shape)"
      ],
      "metadata": {
        "id": "EC2_UouzO5mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To statistically test if the train and test representative of the overall data, would compute the Median for the independent variables for both the test and train sets."
      ],
      "metadata": {
        "id": "vP_30OzEO8Z7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# median for y_train\n",
        "median_y_train = Y_train.median()\n",
        "\n",
        "# median for y_test\n",
        "median_y_test = Y_test.median()"
      ],
      "metadata": {
        "id": "_S_osMs5O-eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The median for Y Train variables is:',median_y_train)"
      ],
      "metadata": {
        "id": "zinPVR5WPAjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The median for Y Test variables is:',median_y_test)"
      ],
      "metadata": {
        "id": "AAlIHIiKPCaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion:\n",
        "\n",
        "Based on the above result, we can conclude statistically that the train and test representative of the overall data as the median for both y_train and y_test are similar."
      ],
      "metadata": {
        "id": "0w74MSJ_PFvZ"
      }
    }
  ]
}